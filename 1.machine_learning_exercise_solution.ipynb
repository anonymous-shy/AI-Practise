{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小象学院机器学习集训营-第1阶段-机器学习建模-作业1\n",
    "\n",
    "**考试说明:**\n",
    "\n",
    "- 以下为小象学院机器学习集训营第1阶段数据分析部分作业\n",
    "    - **习题部分**包含**问答题**和**代码填充题**\n",
    "    - **总结部分**可以对本部分学习内容进行总结和梳理，也可以对课程与服务进行反馈\n",
    "\n",
    "> 提示：大家将使用 jupyter Notebook 来完成项目。\n",
    "    - 问答题部分，可以在cell中作答，如果开启Markdown格式，可以参考[作业部落Markdown说明](https://www.zybuluo.com/mdeditor)给出的Markdown语法格式说明。\n",
    "    - 代码题部分，你可以通过单击代码区域，然后使用键盘快捷键 Shift+Enter 或 Shift+Return 来运行代码。或者在选择代码后使用执行（run cell）按钮执行代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简答题(共4题，每题5分，共计20分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 请写出你了解的机器学习特征工程操作，以及它的意义（面试题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征工程**\n",
    "\n",
    "- 1.数值幅度缩放:log,MinMax,Z-score\n",
    "- 2.统计结果作为新特征\n",
    "- 3.缺失值处理\n",
    "- 4.高次特征和交叉特征   \n",
    "   - 通过生成高次项特征增加维度 PolynomialFeatures专门产生多项式的，并且多项式包含的是相互影响的特征集。\n",
    "   比如：一个输入样本是２维的。形式如[a,b] ,则二阶多项式的特征集如下[1,a,b,a^2,ab,b^2]\n",
    "- 5.离散化、分箱、分桶   \n",
    "   - 等距离cut：按等间距切分 等频qcut：百分比切分\n",
    "- 6.独热向量编码\n",
    "- 7.时间日期型   \n",
    "   - 可以得到其他维度的时间特征\n",
    "- 8.组合特征\n",
    "\n",
    "**特征选择**\n",
    "- 1.过滤式/Filter（较少使用） 根据每一列与target的相关性选择\n",
    "- 2.包裹式/wrapper RFE,递归去除列评估结果\n",
    "- 3.嵌入式/Embedded\n",
    "\n",
    "**意义总结**：\n",
    "特征工程是从原始数据中去除噪音、提取有用信息的过程，提取后的特征能够最大限度地反映数据的统计特性，对最终的预测和分类有更强的表现力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 请写出上述特征工程操作的sklearn或者pandas实现方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.幅度缩放**\n",
    "```python\n",
    "df.Age.apply(np.log)\n",
    "sklearn:MinMaxScaler\n",
    "sklearn:StandardScaler\n",
    "```\n",
    "**2.统计结果作为特征**\n",
    "```python\n",
    "df_train.loc[:,'FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 \n",
    "df_train.sample(10)\n",
    "```\n",
    "**3.缺失值处理**\n",
    "```python\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\n",
    "```\n",
    "**4.高次特征和交叉特征**\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit_transform(df_train[['SibSp','Parch']])\n",
    "```\n",
    "**5.归一化**\n",
    "```python\n",
    "Normalizer()\n",
    "```\n",
    "**6.独热向量编码**\n",
    "```python\n",
    "pandas.get_dummies()\n",
    "skelarn:OneHotEncoder\n",
    "```\n",
    "\n",
    "**7.日期时间**\n",
    "```python\n",
    "pandas:to_datetime\n",
    "dt.month dt.dayofweek dt.dayofyear\n",
    "```\n",
    "\n",
    "**8.文本**\n",
    "````python\n",
    "sklearn:CountVectorizer\n",
    "sklearn:TfidfVectorizer\n",
    "gensim:word2vec\n",
    "````\n",
    "\n",
    "\n",
    "特征选择：\n",
    "\n",
    "**1.过滤式/Filter**\n",
    "根据每一列与target的相关性选择\n",
    "```python\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import numpy as np\n",
    "select = SelectPercentile(percentile=70)\n",
    "```python\n",
    "**2.包裹式/wrapper**\n",
    "RFE,递归去除列评估结果\n",
    "```python\n",
    "from sklearn.feature_selection import RFE\n",
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=40)\n",
    "#select = RFE(LogisticRegression(penalty=\"l1\"), n_features_to_select=40)\n",
    "```\n",
    "\n",
    "**3.嵌入式/Embedded**\n",
    "```python\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold=\"median\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型评估中的留一法，留出法，交叉验证分别是什么操作？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**留一法：**\n",
    "就是每次只留下一个样本做测试集，其它样本做训练集，如果有k个样本，则需要训练k次，测试k次。\n",
    "\n",
    "**留出法：**\n",
    "把D划分为两部分：训练集S和测试集T，在S上训练，在T上做测试。\n",
    "\n",
    "**交叉验证:**\n",
    "将训练集划分为K折，取一部分作为测试集，其他K-1部分作为训练集，对训练集训练后，然后切换训练集-测试集，从K-1的部分中选取一个测试机，剩下的作为训练集，然后在训练模型，这样循环完毕K折，得到的结果求平均。\n",
    "\n",
    "**步骤：**\n",
    "\n",
    "1、将全部训练集 S分成 k个不相交的子集，假设 S中的训练样例个数为 m，那么每一个子 集有 m/k 个训练样例，，相应的子集称作 {s1,s2,…,sk}。   \n",
    "2、每次从分好的子集中里面，拿出一个作为测试集，其它k-1个作为训练集   \n",
    "3、根据训练训练出模型或者假设函数。   \n",
    "4、把这个模型放到测试集上，得到分类率。   \n",
    "5、计算k次求得的分类率的平均值，作为该模型或者假设函数的真实分类率。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如何理解模型的过拟合与欠拟合，以及如何解决？（面试题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**欠拟合：**\n",
    "\n",
    "模型表达能力弱，不能完全拟合数据集。\n",
    "\n",
    "**缓解欠拟合：**\n",
    "\n",
    "增加维度特征，可以通过多项式高次特征、统计等方式增加新的维度\n",
    "\n",
    "**过拟合：**\n",
    "\n",
    "模型过于拟合训练集，导致对于一些噪声误差数据也进行了拟合，这样的模型泛化能力较差。说直白就是对训练集进行了”死记硬背“，会导致到了测试集上无法拟合。\n",
    "\n",
    "**缓解过拟合:**\n",
    "\n",
    "对某些模型来讲最粗暴的方式就是直接增加训练集的大小   \n",
    "在代价函数后面添加正则化项（L1、L2正则），例如lasso和ridge等   \n",
    "bagging方式中的投票机制和bootstrap，例如随机森林等,让每棵树只看到一部分样本   \n",
    "树模型中可以对树的深度、叶子结点个数等参数进行限制，防止模型过拟合   \n",
    "树模型的剪枝操作   \n",
    "神经网络中的dropout等   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码操作题(共1题，共计80分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信用卡欺诈项目(共7项，前5项每题10分，6，7题每题15分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 前期数据导入,预览及处理(此部分勿修改，涉及的数据文件无需复制移动)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T07:38:19.445066Z",
     "start_time": "2019-06-10T07:38:03.408607Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines   age  \\\n",
       "0                 1                              0.766127  45.0   \n",
       "1                 0                              0.957151  40.0   \n",
       "2                 0                              0.658180  38.0   \n",
       "3                 0                              0.233810  30.0   \n",
       "4                 0                              0.907239  49.0   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                   2.0   0.802982         9120.0   \n",
       "1                                   0.0   0.121876         2600.0   \n",
       "2                                   1.0   0.085113         3042.0   \n",
       "3                                   0.0   0.036050         3300.0   \n",
       "4                                   1.0   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                             13.0                      0.0   \n",
       "1                              4.0                      0.0   \n",
       "2                              2.0                      1.0   \n",
       "3                              5.0                      0.0   \n",
       "4                              7.0                      0.0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                           6.0                                   0.0   \n",
       "1                           0.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           0.0                                   0.0   \n",
       "4                           1.0                                   0.0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 2.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import zipfile\n",
    "with zipfile.ZipFile('./data/KaggleCredit2.csv.zip', 'r') as z:\n",
    "    f = z.open('KaggleCredit2.csv')\n",
    "    data = pd.read_csv(f, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T07:38:21.656925Z",
     "start_time": "2019-06-10T07:38:21.649944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112915, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T07:38:22.367202Z",
     "start_time": "2019-06-10T07:38:22.341228Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs                           0\n",
       "RevolvingUtilizationOfUnsecuredLines       0\n",
       "age                                     4267\n",
       "NumberOfTime30-59DaysPastDueNotWorse       0\n",
       "DebtRatio                                  0\n",
       "MonthlyIncome                              0\n",
       "NumberOfOpenCreditLinesAndLoans            0\n",
       "NumberOfTimes90DaysLate                    0\n",
       "NumberRealEstateLoansOrLines               0\n",
       "NumberOfTime60-89DaysPastDueNotWorse       0\n",
       "NumberOfDependents                      4267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T07:38:23.340521Z",
     "start_time": "2019-06-10T07:38:22.914007Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.loc[:,'shapey'] = data['SeriousDlqin2yrs']\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T07:38:23.400330Z",
     "start_time": "2019-06-10T07:38:23.387362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06742876076872101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['SeriousDlqin2yrs']\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T07:38:28.399071Z",
     "start_time": "2019-06-10T07:38:28.356186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 108648 entries, 0 to 112914\n",
      "Data columns (total 11 columns):\n",
      "RevolvingUtilizationOfUnsecuredLines    108648 non-null float64\n",
      "age                                     108648 non-null float64\n",
      "NumberOfTime30-59DaysPastDueNotWorse    108648 non-null float64\n",
      "DebtRatio                               108648 non-null float64\n",
      "MonthlyIncome                           108648 non-null float64\n",
      "NumberOfOpenCreditLinesAndLoans         108648 non-null float64\n",
      "NumberOfTimes90DaysLate                 108648 non-null float64\n",
      "NumberRealEstateLoansOrLines            108648 non-null float64\n",
      "NumberOfTime60-89DaysPastDueNotWorse    108648 non-null float64\n",
      "NumberOfDependents                      108648 non-null float64\n",
      "shapey                                  108648 non-null int64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 9.9 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 以下为操作题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 把数据切分成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T07:39:03.430220Z",
     "start_time": "2019-06-10T07:39:03.401265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76053, 11) (32595, 11) (76053,) (32595,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "train_x,test_x,train_y,test_y  = train_test_split(X,y,test_size=0.3)\n",
    "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用logistic regression建模，并且输出一下系数，分析重要度。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T03:28:06.870324Z",
     "start_time": "2019-03-19T03:28:06.226580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)> [[-2.15288005e-04 -5.97490971e-02  1.74068288e-01 -5.05115388e-02\n",
      "  -8.96274325e-06 -4.30693126e-02  5.56359600e-02  3.18757079e-02\n",
      "  -2.30294178e-01 -1.15773665e-01  1.32483874e+01]] [-3.09071253]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "lr.fit(train_x,train_y)\n",
    "lr.predict(test_x)\n",
    "print(lr.get_params,lr.coef_,lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     30383\n",
      "           1       1.00      1.00      1.00      2212\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     32595\n",
      "   macro avg       1.00      1.00      1.00     32595\n",
      "weighted avg       1.00      1.00      1.00     32595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(lr.predict(test_x), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用决策树/SVM/KNN...等sklearn分类算法进行分类，尝试了解参数含义，调整不同的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T03:28:07.950594Z",
     "start_time": "2019-03-19T03:28:07.599807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 参数 \n",
    "#  criterion：树结点分裂标准，可选Gini/entropy\n",
    "#  max_depth：树的最大深度\n",
    "#  random_state：The minimum number of samples required to split an internal node\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0, class_weight='balanced')\n",
    "tree.fit(train_x, train_y)\n",
    "\n",
    "#default CART\n",
    "tree_Gini = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "tree_Gini.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     30383\n",
      "           1       1.00      1.00      1.00      2212\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     32595\n",
      "   macro avg       1.00      1.00      1.00     32595\n",
      "weighted avg       1.00      1.00      1.00     32595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(tree_Gini.predict(test_x), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T07:39:34.136258Z",
     "start_time": "2019-06-10T07:39:06.544231Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=2.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "# C:误差项的惩罚参数c\n",
    "# kernel:核函数\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=0, class_weight='balanced')\n",
    "svm.fit(train_x.head(500), train_y.head(500))\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', C=2.0, random_state=0, class_weight='balanced')\n",
    "svm_rbf.fit(train_x.head(500), train_y.head(500)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     32558\n",
      "           1       0.00      0.08      0.00        37\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     32595\n",
      "   macro avg       0.50      0.51      0.48     32595\n",
      "weighted avg       1.00      0.93      0.96     32595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(svm_rbf.predict(test_x), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T03:28:42.950184Z",
     "start_time": "2019-03-19T03:28:42.864431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# n_neighbors ：分组\n",
    "# p：Power parameter for the Minkowski metric.\n",
    "# metric：the distance metric to use for the tree.\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "knn.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     32491\n",
      "           1       0.02      0.40      0.04       104\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     32595\n",
      "   macro avg       0.51      0.67      0.50     32595\n",
      "weighted avg       0.99      0.93      0.96     32595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(knn.predict(test_x), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用网格搜索交叉验证进行逻辑回归/随机森林/Xgboost/LightGBM调参\n",
    "    - tips:特别注意此处的正负样本不均衡，以及选择什么样的评估准则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x111c0b990>,\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=None, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 20, 50], 'max_depth': [4, 5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator = RandomForestClassifier(class_weight='balanced'),\n",
    "    param_grid = {'n_estimators': [10, 20, 50],\n",
    "                  'max_depth': [4,5,6,7]},\n",
    "    cv=StratifiedKFold(n_splits=3).split(train_x, train_y)\n",
    ")\n",
    "\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 50}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     30383\n",
      "           1       1.00      1.00      1.00      2212\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     32595\n",
      "   macro avg       1.00      1.00      1.00     32595\n",
      "weighted avg       1.00      1.00      1.00     32595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(clf.best_estimator_.predict(test_x), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x11c1dbd00>,\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
       "       colsample_bylevel=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 20, 50], 'max_depth': [3, 4, 5, 6], 'subsample': [0.6, 0.7, 0.8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator = XGBClassifier(class_weight='balanced'),\n",
    "    param_grid = {'n_estimators': [10, 20, 50],\n",
    "                  'max_depth': [3,4,5,6],\n",
    "                  'subsample':[0.6, 0.7, 0.8]},\n",
    "    cv=StratifiedKFold(n_splits=3).split(train_x, train_y)\n",
    ")\n",
    "\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 10, 'subsample': 0.6}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     30383\n",
      "           1       1.00      1.00      1.00      2212\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     32595\n",
      "   macro avg       1.00      1.00      1.00     32595\n",
      "weighted avg       1.00      1.00      1.00     32595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(clf.best_estimator_.predict(test_x), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x11cd88eb8>,\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "        colsample_bytree=1.0, learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 20, 50], 'max_depth': [3, 4, 5, 6], 'subsample': [0.6, 0.7, 0.8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator = LGBMClassifier(class_weight='balanced'),\n",
    "    param_grid = {'n_estimators': [10, 20, 50],\n",
    "                  'max_depth': [3,4,5,6],\n",
    "                  'subsample':[0.6, 0.7, 0.8]},\n",
    "    cv=StratifiedKFold(n_splits=3).split(train_x, train_y)\n",
    ")\n",
    "\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 10, 'subsample': 0.6}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     30383\n",
      "           1       1.00      1.00      1.00      2212\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     32595\n",
      "   macro avg       1.00      1.00      1.00     32595\n",
      "weighted avg       1.00      1.00      1.00     32595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(clf.best_estimator_.predict(test_x), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 查看sklearn的官方说明，了解混淆矩阵等评估标准，并对此例进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T03:29:16.494458Z",
     "start_time": "2019-03-19T03:29:16.444020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵：\n",
      " [[30383     0]\n",
      " [    0  2212]]\n"
     ]
    }
   ],
   "source": [
    "# 混淆矩阵是预测值与实际值得交叉情况。列代表预测的数据类别，行代表实际的类别\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "matrix = confusion_matrix(test_y, clf.best_estimator_.predict(test_x))\n",
    "TP = matrix[0,0]\n",
    "FP = matrix[0,1]\n",
    "FN = matrix[1,0]\n",
    "TN = matrix[1,1]\n",
    "print('混淆矩阵：\\n',matrix)\n",
    "# 结果中，30318表示预测为正样本并且实际为正样本的数量。第一行第二列表示预测为负样本，实际为正样本的数量是0\n",
    "# 第二行第一列表示实际为负样本预测为正样本的数量是0，第二行第二列表示实际为负样本预测为负样本的数量为2212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 银行通常会有更严格的要求，因为fraud带来的后果通常比较严重，一般我们会调整模型的标准。   \n",
    "比如在各种分类模型当中，一般我们的概率判定边界为0.5，但是我们可以把阈值设定低一些，来提高模型的“敏感度”   \n",
    "试试看把阈值设定为0.3，再看看这个时候的混淆矩阵等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T03:29:22.615864Z",
     "start_time": "2019-03-19T03:29:22.585810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thredhold = 0.3 LR:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     30383\n",
      "           1       0.97      0.55      0.70      2212\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     32595\n",
      "   macro avg       0.97      0.78      0.84     32595\n",
      "weighted avg       0.97      0.97      0.96     32595\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(train_x,train_y)\n",
    "lr_proba = lr.predict_proba(test_x)\n",
    "proba = lr_proba[:,1] > 0.3\n",
    "print(\"thredhold = 0.3 LR:\\n\",classification_report(test_y, proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 尝试对不同特征的重要度进行排序，通过特征选择的方式，对特征进行筛选。并重新建模，观察此时的模型准确率等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T03:29:26.646190Z",
     "start_time": "2019-03-19T03:29:26.615712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征得分： [8.39360520e-01 8.34542217e+02 1.15863190e+03 2.29085062e+02\n",
      " 5.96947546e+01 9.88474029e+01 9.73928546e+02 6.40000139e+01\n",
      " 6.86318336e+02 1.60660080e+02            inf]\n",
      "筛选前的维度： (76053, 11)\n",
      "筛选后的维度： (76053, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  7,  5,  9,  3,  8,  1,  6,  2, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter \n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import numpy as np\n",
    "select = SelectPercentile(percentile=70)\n",
    "select.fit(train_x, train_y)\n",
    "# transform training set:\n",
    "X_train_selected = select.transform(train_x)\n",
    "print('特征得分：',select.scores_)\n",
    "print('筛选前的维度：',train_x.shape)\n",
    "print('筛选后的维度：',X_train_selected.shape)\n",
    "np.argsort(select.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T03:29:28.108561Z",
     "start_time": "2019-03-19T03:29:27.733799Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     30409\n",
      "           1       0.07      1.00      0.13      2186\n",
      "\n",
      "   micro avg       0.07      0.07      0.07     32595\n",
      "   macro avg       0.53      0.50      0.06     32595\n",
      "weighted avg       0.94      0.07      0.01     32595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 基于以上筛选，对筛选后的特征进行建模并评估\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 整理测试集，手动过滤特征集0, 4, 7, 5, 9, 3, 8\n",
    "X_test_selected = test_x.drop([test_x.columns[6],test_x.columns[1],test_x.columns[2]],axis=1)\n",
    "    \n",
    "lr_selected = LogisticRegression()\n",
    "\n",
    "lr_selected.fit(X_train_selected,train_y)\n",
    "pred = lr_selected.predict(X_test_selected)\n",
    "print(\"LR:\\n\",classification_report(test_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本周课程意见反馈(非必答)\n",
    "请大家围绕以下内容进行回答：\n",
    "- 自身总结：您自己在本周课程的学习，收获，技能掌握等方面进行总结，包括自身在哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n",
    "- 课程反馈：也可以就知识点，进度，难易度，辅导方式，考试难度等等进行意见反馈，督促我们进行更有效的改进，为大家提供更优质的服务。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
