{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.0.3\n",
      "numpy 1.18.2\n",
      "pandas 0.25.1\n",
      "sklearn 0.20.1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os \n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\Shy\\scikit_learn_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 8.32520000e+00,  4.10000000e+01,  6.98412698e+00,\n",
      "         1.02380952e+00,  3.22000000e+02,  2.55555556e+00,\n",
      "         3.78800000e+01, -1.22230000e+02],\n",
      "       [ 8.30140000e+00,  2.10000000e+01,  6.23813708e+00,\n",
      "         9.71880492e-01,  2.40100000e+03,  2.10984183e+00,\n",
      "         3.78600000e+01, -1.22220000e+02],\n",
      "       [ 7.25740000e+00,  5.20000000e+01,  8.28813559e+00,\n",
      "         1.07344633e+00,  4.96000000e+02,  2.80225989e+00,\n",
      "         3.78500000e+01, -1.22240000e+02],\n",
      "       [ 5.64310000e+00,  5.20000000e+01,  5.81735160e+00,\n",
      "         1.07305936e+00,  5.58000000e+02,  2.54794521e+00,\n",
      "         3.78500000e+01, -1.22250000e+02],\n",
      "       [ 3.84620000e+00,  5.20000000e+01,  6.28185328e+00,\n",
      "         1.08108108e+00,  5.65000000e+02,  2.18146718e+00,\n",
      "         3.78500000e+01, -1.22250000e+02]])\n",
      "array([4.526, 3.585, 3.521, 3.413, 3.422])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(housing.data[0:5])\n",
    "pprint.pprint(housing.target[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state=2020)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state=211)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaler = scaler.fit_transform(x_train)\n",
    "x_valid_scaler = scaler.transform(x_valid)\n",
    "x_test_scaler = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 函数式API 功能API进行Wide-Deep编程\n",
    "input = keras.layers.Input(shape=x_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "# 复合函数: f(x) = h(g(x))\n",
    "concat = keras.layers.concatenate([input, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "callbakes = [keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 1.0036 - val_loss: 0.5451\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5300 - val_loss: 0.6026\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.9525 - val_loss: 2.6327\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 8.5385 - val_loss: 118.9273\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 57.0528 - val_loss: 159.4713\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shy\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py:1261: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaler, y_train,\n",
    "                   validation_data=(x_valid_scaler, y_valid),\n",
    "                   epochs=100,\n",
    "                   callbacks=callbakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 20us/sample - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaler, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_deep_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              multiple                  270       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  930       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 39        \n",
      "=================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 使用子类API来实现Wide_Deep\n",
    "class WideDeepModel(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(WideDeepModel, self).__init__()\n",
    "        \"\"\"定义模型的层次\"\"\"\n",
    "        self.hidden1_layer = keras.layers.Dense(30, activation='relu')\n",
    "        self.hidden2_layer = keras.layers.Dense(30, activation='relu')\n",
    "        self.output_layer = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, input):\n",
    "        \"\"\"完成模型的正向计算\"\"\"\n",
    "        hidden1 = self.hidden1_layer(input)\n",
    "        hidden2 - self.hidden2_layer(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_layer(concat)\n",
    "        return output\n",
    "    \n",
    "model = WideDeepModel()\n",
    "model.build(input_shape=(None, 8))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "callbakes = [keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0'] when minimizing the loss.\n",
      "   32/11610 [..............................] - ETA: 41sWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "_SymbolicException",
     "evalue": "Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'dense_1/Identity:0' shape=(None, 30) dtype=float32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: dense_1/Identity:0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m_SymbolicException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-274ce02b3ce1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                    callbacks=callbakes)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     73\u001b[0m       raise core._SymbolicException(\n\u001b[0;32m     74\u001b[0m           \u001b[1;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_SymbolicException\u001b[0m: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'dense_1/Identity:0' shape=(None, 30) dtype=float32>]"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaler, y_train,\n",
    "                   validation_data=(x_valid_scaler, y_valid),\n",
    "                   epochs=100,\n",
    "                   callbacks=callbakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 30)           210         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 30)           930         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35)           0           input_10[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            36          concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 多输入\n",
    "input_wide = keras.layers.Input(shape=[5])\n",
    "input_deep = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_deep)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_wide, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs = [input_wide, input_deep], \n",
    "                           outputs=[output])\n",
    "model.summary()\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "callbakes = [keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 1.5969 - val_loss: 0.6989\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.5595 - val_loss: 0.5052\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4498 - val_loss: 0.4524\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4057 - val_loss: 0.4104\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3811 - val_loss: 0.3953\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3669 - val_loss: 0.3771\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3536 - val_loss: 0.3742\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3434 - val_loss: 0.3659\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3453 - val_loss: 0.3662\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3478 - val_loss: 0.3654\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3453 - val_loss: 0.3442\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3330 - val_loss: 0.3513\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3318 - val_loss: 0.3470\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3284 - val_loss: 0.3645\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3298 - val_loss: 0.3443\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3229 - val_loss: 0.3480\n"
     ]
    }
   ],
   "source": [
    "x_train_scaled_wide = x_train_scaler[:, :5]\n",
    "x_train_scaled_deep = x_train_scaler[:, 2:]\n",
    "x_valid_scaled_wide = x_valid_scaler[:, :5]\n",
    "x_valid_scaled_deep = x_valid_scaler[:, 2:]\n",
    "x_test_scaled_wide = x_test_scaler[:, :5]\n",
    "x_test_scaled_deep = x_test_scaler[:, 2:]\n",
    "\n",
    "history = model.fit([x_train_scaled_wide,x_train_scaled_deep], \n",
    "                    y_train,\n",
    "                   validation_data=([x_valid_scaled_wide,\n",
    "                                     x_valid_scaled_deep], \n",
    "                                    y_valid),\n",
    "                   epochs=100,\n",
    "                   callbacks=callbakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV\n",
    "# 1. 转化为sklearn得model\n",
    "# 2. 定义参数集合\n",
    "# 3. 搜索参数\n",
    "\n",
    "def build_model(hidden_layers = 1,\n",
    "               layer_size = 30,\n",
    "               learning_rate = 3e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(layer_size,\n",
    "                                 activation='relu',\n",
    "                                input_shape=x_train.shape[1:]))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(keras.layers.Dense(layer_size,activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
